{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Derivative Rules, Guidelines for Substitution, and Common Function Derivatives\n",
    "\n",
    "This note summarizes essential differentiation rules for deep learning, when to use substitution (aka chain rule), and how to derive common functions like sigmoid and exponentials.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Core Derivative Rules\n",
    "\n",
    "| Rule             | Description                                | Formula |\n",
    "|------------------|--------------------------------------------|---------|\n",
    "| Constant Rule     | Derivative of a constant                   | $\\frac{d}{dx}(c) = 0$ |\n",
    "| Power Rule        | For $x^n$, pull the exponent down          | $\\frac{d}{dx}(x^n) = nx^{n-1}$ |\n",
    "| Sum Rule          | Derivative of a sum = sum of derivatives   | $\\frac{d}{dx}(f + g) = f' + g'$ |\n",
    "| Product Rule      | For multiplying functions                  | $(fg)' = f'g + fg'$ |\n",
    "| Quotient Rule     | For dividing functions                     | $\\left( \\frac{f}{g} \\right)' = \\frac{f'g - fg'}{g^2}$ |\n",
    "| Chain Rule        | For composite functions $f(g(x))$          | $\\frac{d}{dx}f(g(x)) = f'(g(x)) \\cdot g'(x)$ |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Guidelines for Substitution / Chain Rule\n",
    "\n",
    "Use substitution (and chain rule) when:\n",
    "- You're differentiating a **composite function**\n",
    "- The expression includes **something more complex than plain $x$**\n",
    "- Example: $e^{-x}$, $\\log(1 + x^2)$, $\\tanh(x^3)$\n",
    "\n",
    "**Key principle:**  \n",
    "If you're not differentiating directly with respect to $x$, you're likely using the chain rule.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Chain Rule in Action (with $e^{-x}$)\n",
    "\n",
    "Let:\n",
    "- $f(x) = e^{-x}$\n",
    "- Think of this as $f(x) = e^{u(x)}$, where $u(x) = -x$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\frac{d}{dx}(e^{-x}) = e^{-x} \\cdot \\frac{d}{dx}(-x) = e^{-x} \\cdot (-1) = -e^{-x}\n",
    "$$\n",
    "\n",
    "‚úÖ The negative sign comes from the derivative of the inner function ($-x$).\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Derivatives of Common Functions\n",
    "\n",
    "### üî∑ Polynomials:\n",
    "- $\\frac{d}{dx}(x^2) = 2x$\n",
    "- $\\frac{d}{dx}(x^n) = nx^{n-1}$\n",
    "\n",
    "### üî∑ Exponentials:\n",
    "- $\\frac{d}{dx}(e^x) = e^x$\n",
    "- $\\frac{d}{dx}(e^{-x}) = -e^{-x}$\n",
    "- $\\frac{d}{dx}(a^x) = a^x \\log a$\n",
    "\n",
    "### üî∑ Logarithms (natural log):\n",
    "- $\\frac{d}{dx}(\\log x) = \\frac{1}{x}$\n",
    "\n",
    "### üî∑ Trigonometric (FYI only):\n",
    "- $\\frac{d}{dx}(\\sin x) = \\cos x$\n",
    "- $\\frac{d}{dx}(\\cos x) = -\\sin x$\n",
    "- $\\frac{d}{dx}(\\tan x) = \\sec^2 x$\n",
    "\n",
    "### üî∑ Hyperbolic / Neural Net Activations:\n",
    "- $\\frac{d}{dx}(\\tanh x) = 1 - \\tanh^2 x$\n",
    "- $\\frac{d}{dx}(\\text{sigmoid}(x)) = \\sigma(x)(1 - \\sigma(x))$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- Derivative rules = tools. Chain rule = glue.\n",
    "- Substitution helps identify when to apply chain rule\n",
    "- Even simple expressions like $e^{-x}$ are composite under the hood\n",
    "- Practice rewriting and differentiating in baby steps with annotations\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Activation Functions](activations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Intuition Behind Sigmoid vs Tanh in Deep Learning\n",
    "\n",
    "Understanding activation functions isn‚Äôt just about taking derivatives ‚Äî it's about how they behave **during optimization**, especially for **gradient flow**, **convergence speed**, and **vanishing gradients**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. Output Range\n",
    "\n",
    "| Function | Output Range | Zero-Centered? |\n",
    "|----------|--------------|----------------|\n",
    "| Sigmoid  | $(0, 1)$     | ‚ùå No          |\n",
    "| Tanh     | $(-1, 1)$    | ‚úÖ Yes         |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  Zero-centered outputs (like tanh) help gradients flow **positively and negatively**, making weight updates more balanced and efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. Vanishing Gradient Problem\n",
    "\n",
    "Both functions **saturate** when input $x$ is very positive or negative.\n",
    "\n",
    "| Function | Saturation Zones                  | Derivative Trend |\n",
    "|----------|-----------------------------------|------------------|\n",
    "| Sigmoid  | $x < -3$ or $x > 3$ ‚Üí flattens    | Derivative $\\approx 0$ |\n",
    "| Tanh     | $x < -3$ or $x > 3$ ‚Üí flattens    | Derivative $\\approx 0$ |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  When neurons output in these zones, their gradients vanish ‚Üí **very slow training or dead neurons** in deeper layers.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Gradient Strength\n",
    "\n",
    "| Function | Max Derivative | Location     |\n",
    "|----------|----------------|--------------|\n",
    "| Sigmoid  | $0.25$         | At $x = 0$   |\n",
    "| Tanh     | $1.0$          | At $x = 0$   |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  Stronger gradients mean faster updates near $0$ ‚Äî **tanh is more expressive and efficient** in the core training zone.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4. Use Cases in Deep Learning\n",
    "\n",
    "| Use Case                        | Activation |\n",
    "|----------------------------------|------------|\n",
    "| Binary classification output     | Sigmoid    |\n",
    "| Multiclass classification output | Softmax    |\n",
    "| Hidden layers (historically)     | Tanh       |\n",
    "| Modern hidden layers             | ReLU       |\n",
    "\n",
    "- **Why tanh over sigmoid in hidden layers?**  \n",
    "  It's zero-centered and provides stronger gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 5. Why ReLU Took Over\n",
    "\n",
    "While tanh and sigmoid are still useful:\n",
    "- **ReLU** doesn‚Äôt saturate for $x > 0$\n",
    "- It keeps gradients alive\n",
    "- Great for deep networks\n",
    "- Easier to optimize\n",
    "\n",
    "But:\n",
    "- **Sigmoid** is still used in output layers\n",
    "- **Tanh + Sigmoid** still power LSTM/GRU gates\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Visual Summary\n",
    "\n",
    "#### Sigmoid & Tanh\n",
    "\n",
    "- Sigmoid squashes input to $(0, 1)$, flattens out at extremes  \n",
    "- Tanh squashes to $(-1, 1)$, symmetric and zero-centered\n",
    "\n",
    "#### Their Derivatives\n",
    "\n",
    "- **Sigmoid Derivative** peaks at $0.25$ and vanishes quickly  \n",
    "- **Tanh Derivative** peaks at $1$ and is wider around center  \n",
    "- Both die off at $|x| > 3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Activation Functions + Softmax + Cross-Entropy ‚Äî Deep Learning Intuition\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ ReLU (Rectified Linear Unit)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Keep positive values, zero out negatives.\n",
    "- Fast to compute, no saturation in the positive range.\n",
    "\n",
    "**Issues:**\n",
    "- \"Dead neurons\" ‚Äî if a neuron gets stuck negative, it may never recover.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Leaky ReLU\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha x & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "\\quad\\text{where } \\alpha \\approx 0.01 \\text{ or } 0.1\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "\\alpha & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Fixes:**\n",
    "- Lets small gradients pass through for $x < 0$ ‚Üí avoids dead neurons.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "**Exact Formula:**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "= x \\cdot \\frac{1}{2} \\left[ 1 + \\text{erf}\\left( \\frac{x}{\\sqrt{2}} \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Derivative (Exact):**\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\text{GELU}(x) = \\Phi(x) + x \\cdot \\phi(x)\n",
    "\\quad\\text{where } \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "**Approximate Formula (Used in practice):**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5x \\left[ 1 + \\tanh\\left( \\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3) \\right) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax + Cross-Entropy\n",
    "\n",
    "#### Softmax:\n",
    "\n",
    "Given logits vector $ \\mathbf{z} $, softmax converts to probabilities:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross-Entropy Loss:\n",
    "\n",
    "Given true class $ \\mathbf{y} $ (one-hot), and predicted probs $ \\hat{\\mathbf{y}} = \\text{softmax}(\\mathbf{z}) $:\n",
    "\n",
    "$$\n",
    "\\text{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "= -\\log(\\hat{y}_{\\text{true class}})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Combined Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "This is why frameworks like PyTorch use `CrossEntropyLoss(logits, targets)` directly.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Visual Intuitions\n",
    "\n",
    "- Softmax with larger logits ‚Üí more confident predictions (sharper output)\n",
    "- Cross-entropy loss:\n",
    "  - Low when $ \\hat{y}_{\\text{true}} \\approx 1 $\n",
    "  - Very high when $ \\hat{y}_{\\text{true}} \\approx 0 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Activation Functions + Softmax + Cross-Entropy ‚Äî Deep Learning Intuition (With Math)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ ReLU (Rectified Linear Unit)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Outputs the input directly if it's positive, else outputs 0.\n",
    "- Introduces non-linearity while maintaining simplicity.\n",
    "- **No gradient saturation** in the positive region ‚Üí keeps gradients alive.\n",
    "\n",
    "**Drawback:**\n",
    "- Neurons can \"die\" if they fall into the $x \\leq 0$ region (zero gradient forever).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Leaky ReLU\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha x & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "\\quad\\text{where } \\alpha \\in [0.01, 0.1]\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "\\alpha & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Small negative slope instead of flat zero.\n",
    "- Allows small gradient when $x < 0$ ‚Üí avoids dead neurons.\n",
    "- Often used in GANs or deep CNNs for better convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "**Exact Formula:**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\frac{1}{2} \\left[ 1 + \\text{erf}\\left( \\frac{x}{\\sqrt{2}} \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Derivative (Exact)(Product Rule):**\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\text{GELU}(x) = \\Phi(x) + x \\cdot \\phi(x)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "**Approximate Formula (used in practice):**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5x \\left[ 1 + \\tanh\\left( \\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3) \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Smoothed version of ReLU that uses probability weighting.\n",
    "- Weighs inputs by their likelihood of being positive under a standard normal distribution.\n",
    "- No hard threshold ‚Üí smoother gradient flow.\n",
    "\n",
    "**Use case:**\n",
    "- Default activation in Transformer models (e.g. BERT, GPT).\n",
    "- Helps with convergence and generalization in large-scale deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax + Cross-Entropy\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Softmax Function\n",
    "\n",
    "Given raw logits vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = [z_1, z_2, \\dots, z_n]\n",
    "$$\n",
    "\n",
    "Softmax converts it to a probability distribution:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "- Output: $0 < \\hat{y}_i < 1$\n",
    "- Ensures: $\\sum_i \\hat{y}_i = 1$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Cross-Entropy Loss\n",
    "\n",
    "Given one-hot encoded true label $ \\mathbf{y} $ and predicted probabilities $ \\hat{\\mathbf{y}} $, the cross-entropy loss is:\n",
    "\n",
    "$$\n",
    "\\text{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Since only one $ y_i = 1 $, this simplifies to:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\log(\\hat{y}_{\\text{true class}})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Log-Softmax Identity\n",
    "\n",
    "Softmax followed by log simplifies to:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "Used in practice as `log_softmax()` for **numerical stability** (avoids overflow).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Derivative of Softmax + Cross-Entropy\n",
    "\n",
    "Combined, the gradient becomes extremely clean:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "- Just the **difference between predicted and actual class**\n",
    "- Avoids needing to separately backprop through softmax and log\n",
    "- Efficient and stable ‚Äî this is why it‚Äôs **always implemented as a single combined op** in PyTorch/TF\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Visual Insights\n",
    "\n",
    "- **Softmax**:\n",
    "  - With small logit differences ‚Üí soft probability distribution\n",
    "  - With large logit differences ‚Üí sharp confidence spike\n",
    "\n",
    "- **Cross-Entropy**:\n",
    "  - Loss is **low** when the predicted probability for the true class is **close to 1**\n",
    "  - Loss is **high** when the model is confident **but wrong**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Log-Softmax: Full Derivation + Gradient\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. Recall Softmax\n",
    "\n",
    "Given logits:\n",
    "\n",
    "$$\n",
    "z = [z_1, z_2, \\dots, z_n]\n",
    "$$\n",
    "\n",
    "The softmax function is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. Derive Log-Softmax\n",
    "\n",
    "Take the log of softmax:\n",
    "\n",
    "$$\n",
    "\\log(\\hat{y}_i) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "This is the **log-softmax identity**:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Log-Softmax as a Function\n",
    "\n",
    "Let‚Äôs define:\n",
    "\n",
    "$$\n",
    "\\ell_i = \\log(\\text{softmax}(z_i)) = z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "We want to compute the derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Case 1: $i = k$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_i} =\n",
    "\\frac{\\partial}{\\partial z_i} \\left( z_i - \\log \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Split it:\n",
    "\n",
    "- First term: $ \\frac{\\partial z_i}{\\partial z_i} = 1 $\n",
    "- Second term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_i} \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "= \\frac{e^{z_i}}{\\sum_j e^{z_j}} = \\hat{y}_i\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_i} = 1 - \\hat{y}_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Case 2: $i \\ne k$\n",
    "\n",
    "Only the second term depends on $z_k$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k} = -\\frac{\\partial}{\\partial z_k} \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "= -\\frac{e^{z_k}}{\\sum_j e^{z_j}} = -\\hat{y}_k\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4. Final Result ‚Äî Jacobian of Log-Softmax\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k} =\n",
    "\\begin{cases}\n",
    "1 - \\hat{y}_i & \\text{if } i = k \\\\\n",
    "-\\hat{y}_k & \\text{if } i \\ne k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is the **Jacobian matrix** of log-softmax, and it's used in general backprop.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 5. Cross-Entropy with Log-Softmax (Combined)\n",
    "\n",
    "Cross-entropy loss:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "= -\\sum_i y_i \\cdot \\ell_i\n",
    "$$\n",
    "\n",
    "Now take derivative of $L$ w.r.t. logits $z_k$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k}\n",
    "= -\\sum_i y_i \\cdot \\frac{\\partial \\ell_i}{\\partial z_k}\n",
    "$$\n",
    "\n",
    "Now plug in the two cases from above:\n",
    "\n",
    "- When $i = k$: contributes $y_k (1 - \\hat{y}_k)$\n",
    "- When $i \\ne k$: contributes $y_i (-\\hat{y}_k)$\n",
    "\n",
    "So total derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} =\n",
    "- \\left( y_k (1 - \\hat{y}_k) + \\sum_{i \\ne k} y_i (-\\hat{y}_k) \\right)\n",
    "$$\n",
    "\n",
    "Factor out $\\hat{y}_k$:\n",
    "\n",
    "$$\n",
    "= -y_k (1 - \\hat{y}_k) + \\hat{y}_k \\sum_{i \\ne k} y_i\n",
    "$$\n",
    "\n",
    "Since $\\sum_i y_i = 1$, we know $\\sum_{i \\ne k} y_i = 1 - y_k$, so:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} =\n",
    "- y_k + \\hat{y}_k\n",
    "$$\n",
    "\n",
    "Rewritten:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Takeaway\n",
    "\n",
    "- This is why softmax + cross-entropy are **always combined**\n",
    "- The gradient simplifies to:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{z}} L = \\hat{\\mathbf{y}} - \\mathbf{y}\n",
    "$$\n",
    "\n",
    "- No need to manually backprop through softmax or log\n",
    "- Frameworks like PyTorch use this exact trick for `CrossEntropyLoss(logits, labels)`\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Summary\n",
    "\n",
    "| Component | Expression |\n",
    "|-----------|------------|\n",
    "| Log-Softmax | $ \\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j} $ |\n",
    "| $\\frac{\\partial \\ell_i}{\\partial z_k}$ | $ 1 - \\hat{y}_i$ if $i=k$, else $-\\hat{y}_k$ |\n",
    "| Cross-Entropy | $ L = -\\sum_i y_i \\log(\\hat{y}_i) $ |\n",
    "| Final Gradient | $ \\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k $ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Log of Softmax ‚Äî What It Actually Means (Step-by-Step Breakdown)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Goal:\n",
    "\n",
    "Understand the identity:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Example Logits:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "z = [2.0, 1.0, 0.1]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Step 1: Compute Softmax\n",
    "\n",
    "The softmax formula is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "Numerically:\n",
    "\n",
    "- $e^2 \\approx 7.39$\n",
    "- $e^1 \\approx 2.72$\n",
    "- $e^{0.1} \\approx 1.105$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\sum_j e^{z_j} \\approx 7.39 + 2.72 + 1.105 = 11.215\n",
    "$$\n",
    "\n",
    "Softmax outputs:\n",
    "\n",
    "- $\\hat{y}_0 = \\frac{7.39}{11.215} \\approx 0.659$\n",
    "- $\\hat{y}_1 = \\frac{2.72}{11.215} \\approx 0.242$\n",
    "- $\\hat{y}_2 = \\frac{1.105}{11.215} \\approx 0.099$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Step 2: Take the Log of Softmax\n",
    "\n",
    "Now we compute:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log \\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= \\log(e^{z_i}) - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "= z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Numerical Example for $z_0 = 2.0$\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(2.0)) = 2.0 - \\log(11.215) \\approx 2.0 - 2.417 = -0.417\n",
    "$$\n",
    "\n",
    "Other entries:\n",
    "\n",
    "- $\\log(\\text{softmax}(1.0)) \\approx 1.0 - 2.417 = -1.417$\n",
    "- $\\log(\\text{softmax}(0.1)) \\approx 0.1 - 2.417 = -2.317$\n",
    "\n",
    "---\n",
    "\n",
    "### üß® Common Mistake Explained\n",
    "\n",
    "If you saw something like:\n",
    "\n",
    "$$\n",
    "2 - (-0.417) = 2.417 \\Rightarrow \\text{(wrong interpretation)}\n",
    "$$\n",
    "\n",
    "You probably did:\n",
    "\n",
    "$$\n",
    "2 - \\log(\\text{softmax}(2.0)) = 2 - \\log(0.659) \\approx 2 - (-0.417) = 2.417\n",
    "$$\n",
    "\n",
    "That‚Äôs **not** how log-softmax works ‚Äî that‚Äôs *backing out the log of the softmax probability*, not applying log to softmax directly.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Takeaway:\n",
    "\n",
    "To compute log-softmax **correctly**:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "This is:\n",
    "- **Numerically stable**\n",
    "- **Logically correct**\n",
    "- **Used in all deep learning frameworks** (e.g., `log_softmax()` in PyTorch)\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Combined Log-Softmax + Cross-Entropy ‚Äî Why Gradient is $\\hat{y} - y$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. What Happens Separately\n",
    "\n",
    "Logits:\n",
    "\n",
    "$$\n",
    "z = [2.0, 1.0, 0.1]\n",
    "$$\n",
    "\n",
    "Softmax:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\Rightarrow \\hat{y} \\approx [0.71, 0.21, 0.08]\n",
    "$$\n",
    "\n",
    "Cross-entropy loss with true label $y = [1, 0, 0]$:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i) = -\\log(0.71) \\approx 0.342\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. What Happens When Combined\n",
    "\n",
    "Instead of computing softmax and log separately:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "So cross-entropy becomes:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\cdot \\left(z_i - \\log \\sum_j e^{z_j}\\right)\n",
    "= -\\sum_i y_i z_i + \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Derivative of Cross-Entropy w.r.t. Logits $z_k$\n",
    "\n",
    "Take derivative of:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i z_i + \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "Split into two parts:\n",
    "\n",
    "#### (1) First term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_k} \\left( -\\sum_i y_i z_i \\right) = -y_k\n",
    "$$\n",
    "\n",
    "#### (2) Second term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_k} \\left( \\log \\sum_j e^{z_j} \\right) = \\frac{e^{z_k}}{\\sum_j e^{z_j}} = \\hat{y}_k\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Result:\n",
    "\n",
    "Add both parts:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k\n",
    "$$\n",
    "\n",
    "This gives you **clean, simple gradients** from raw logits ‚Äî no need to manually softmax first.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Summary\n",
    "\n",
    "| Concept                     | Formula |\n",
    "|----------------------------|---------|\n",
    "| Softmax                    | $ \\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}} $ |\n",
    "| Log-Softmax                | $ \\log(\\hat{y}_i) = z_i - \\log \\sum_j e^{z_j} $ |\n",
    "| Cross-Entropy Loss         | $ L = -\\sum_i y_i \\log(\\hat{y}_i) $ |\n",
    "| Combined Derivative        | $ \\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k $ |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Deep Learning Math Essentials: Exponentials, Logarithms, and Their Role in Loss Functions\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What is $e$?\n",
    "\n",
    "- $e \\approx 2.718$ is Euler's number.\n",
    "- Defined by:\n",
    "\n",
    "$$\n",
    "e = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n} \\right)^n\n",
    "$$\n",
    "\n",
    "- Unique property:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} e^x = e^x\n",
    "$$\n",
    "\n",
    "Used heavily in deep learning because it provides smooth, always-positive, non-vanishing gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Exponential Function: $e^x$\n",
    "\n",
    "- Always positive: $e^x > 0$\n",
    "- Grows rapidly as $x \\to \\infty$\n",
    "- Flattens near zero as $x \\to -\\infty$\n",
    "- Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} e^x = e^x\n",
    "$$\n",
    "\n",
    "- Operations:\n",
    "  - $e^{a + b} = e^a \\cdot e^b$\n",
    "  - $e^{a - b} = \\frac{e^a}{e^b}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Logarithmic Function: $\\log(x)$\n",
    "\n",
    "- Inverse of $e^x$\n",
    "- Defined as:\n",
    "\n",
    "$$\n",
    "\\log(x) = y \\iff e^y = x\n",
    "$$\n",
    "\n",
    "- Only defined for $x > 0$\n",
    "- Grows slowly, explodes negatively as $x \\to 0^+$\n",
    "- Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\log(x) = \\frac{1}{x}\n",
    "$$\n",
    "\n",
    "- Operation rules:\n",
    "  - $\\log(ab) = \\log a + \\log b$\n",
    "  - $\\log\\left(\\frac{a}{b}\\right) = \\log a - \\log b$\n",
    "  - $\\log(a^b) = b \\log a$\n",
    "  - $\\log(e^x) = x$\n",
    "  - $e^{\\log(x)} = x$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Inverse Identity\n",
    "\n",
    "Exponentials and logs undo each other:\n",
    "\n",
    "$$\n",
    "\\log(e^x) = x \\quad \\text{and} \\quad e^{\\log(x)} = x\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Why Use $\\log$ and $e^x$ in Deep Learning?\n",
    "\n",
    "| Purpose                            | Example                                           | Why                         |\n",
    "|-----------------------------------|---------------------------------------------------|------------------------------|\n",
    "| Convert scores to probabilities   | $\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$ | $e^x$ exaggerates differences |\n",
    "| Stabilize products                | $\\log(p_1 \\cdot p_2) = \\log p_1 + \\log p_2$       | Avoids underflow             |\n",
    "| Gradient-based optimization       | $\\frac{d}{dx} e^x,\\ \\frac{d}{dx} \\log(x)$         | Smooth derivatives           |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Binary Cross-Entropy (BCE)\n",
    "\n",
    "Used in binary classification tasks:\n",
    "\n",
    "$$\n",
    "\\text{BCE}(\\hat{y}, y) = -[y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y \\in \\{0, 1\\}$ is the true label\n",
    "- $\\hat{y} \\in (0, 1)$ is the predicted probability\n",
    "\n",
    "Special cases:\n",
    "- If $y = 1$: $\\text{Loss} = -\\log(\\hat{y})$\n",
    "- If $y = 0$: $\\text{Loss} = -\\log(1 - \\hat{y})$\n",
    "\n",
    "Gradients:\n",
    "- If $y = 1$: $\\frac{dL}{d\\hat{y}} = -\\frac{1}{\\hat{y}}$\n",
    "- If $y = 0$: $\\frac{dL}{d\\hat{y}} = \\frac{1}{1 - \\hat{y}}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax Function\n",
    "\n",
    "Used to convert logits to a probability distribution:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "Properties:\n",
    "- $\\hat{y}_i \\in (0, 1)$\n",
    "- $\\sum_i \\hat{y}_i = 1$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cross-Entropy Loss (Multiclass)\n",
    "\n",
    "With one-hot true labels:\n",
    "\n",
    "$$\n",
    "\\text{CE}(y, \\hat{y}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "If class $k$ is true, and $y_k = 1$:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\log(\\hat{y}_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log-Softmax Trick\n",
    "\n",
    "Instead of computing:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "$$\n",
    "\n",
    "Use:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left(\\sum_j e^{z_j}\\right)\n",
    "$$\n",
    "\n",
    "This is numerically stable and gives clean gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ KL Divergence\n",
    "\n",
    "Measures how much one distribution $Q$ diverges from a true distribution $P$:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log\\left(\\frac{P(i)}{Q(i)}\\right)\n",
    "$$\n",
    "\n",
    "Can be rewritten as:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P)\n",
    "$$\n",
    "\n",
    "- $H(P, Q)$ = cross-entropy\n",
    "- $H(P)$ = entropy of true distribution\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Summary\n",
    "\n",
    "| Concept             | Formula                                                        | Use Case                     |\n",
    "|---------------------|----------------------------------------------------------------|------------------------------|\n",
    "| Exponential         | $e^x$                                                          | Amplify scores (softmax)     |\n",
    "| Logarithm           | $\\log(x)$                                                      | Stabilize, inverse of $e^x$  |\n",
    "| BCE                 | $- [y \\log(\\hat{y}) + (1-y) \\log(1 - \\hat{y})]$                | Binary classification        |\n",
    "| Softmax             | $\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$                  | Convert logits to probs      |\n",
    "| Cross-Entropy       | $-\\sum_i y_i \\log(\\hat{y}_i)$                                   | Multiclass classification    |\n",
    "| Log-Softmax         | $z_i - \\log \\sum_j e^{z_j}$                                     | Numerically stable softmax   |\n",
    "| KL Divergence       | $\\sum_i P(i) \\log \\frac{P(i)}{Q(i)}$                            | Measure distribution mismatch|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• KL Divergence in Deep Learning ‚Äî Full Intuition + Math\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What is KL Divergence?\n",
    "\n",
    "KL divergence measures **how different** a predicted probability distribution $Q$ is from a reference (true) distribution $P$:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log \\left( \\frac{P(i)}{Q(i)} \\right)\n",
    "$$\n",
    "\n",
    "> Read as: ‚ÄúKL of $P$ relative to $Q$‚Äù\n",
    "\n",
    "- It is **not symmetric**:\n",
    "  $$\n",
    "  D_{\\text{KL}}(P \\parallel Q) \\ne D_{\\text{KL}}(Q \\parallel P)\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log Rule Breakdown\n",
    "\n",
    "We can break the KL formula using log rules:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{P(i)}{Q(i)}\\right) = \\log P(i) - \\log Q(i)\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) [\\log P(i) - \\log Q(i)] = H(P, Q) - H(P)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $H(P, Q)$ is the **cross-entropy**\n",
    "- $H(P)$ is the **entropy** of the true distribution\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When $P$ is One-Hot (Normal Classification)\n",
    "\n",
    "Let:\n",
    "$$\n",
    "P = [0, 1, 0] \\quad \\text{(true class is index 1)}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $\\log P(i)$ is only defined for $i=1$ ‚Üí others contribute 0\n",
    "- So:\n",
    "  $$\n",
    "  H(P) = -\\sum_i P(i) \\log P(i) = 0\n",
    "  $$\n",
    "\n",
    "And:\n",
    "\n",
    "$$\n",
    "H(P, Q) = -\\sum_i P(i) \\log Q(i) = -\\log Q(1)\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = -\\log Q(\\text{true class})\n",
    "$$\n",
    "\n",
    "‚úÖ KL = Cross-Entropy\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When $P$ is NOT One-Hot (Soft Targets)\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "P = [0.7,\\ 0.2,\\ 0.1], \\quad Q = [0.6,\\ 0.3,\\ 0.1]\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $H(P, Q) = -\\sum_i P(i) \\log Q(i)$\n",
    "- $H(P) = -\\sum_i P(i) \\log P(i)$\n",
    "- $D_{\\text{KL}} = H(P, Q) - H(P)$\n",
    "\n",
    "Now KL $\\ne$ CE. The **difference reflects how much Q diverges from the full shape of P**, not just its top class.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Intuition\n",
    "\n",
    "- KL divergence measures the **inefficiency** of assuming $Q$ when the true distribution is $P$\n",
    "- It quantifies the **extra bits of information** needed to encode samples from $P$ using $Q$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Connection to Maximum Likelihood\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) seeks to:\n",
    "\n",
    "$$\n",
    "\\arg\\max_\\theta \\sum_x \\log Q_\\theta(x)\n",
    "$$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$\n",
    "\\arg\\min_\\theta D_{\\text{KL}}(P \\parallel Q_\\theta)\n",
    "$$\n",
    "\n",
    "‚úÖ Minimizing KL divergence = Maximizing log-likelihood\n",
    "\n",
    "They are mathematically tied:\n",
    "- **KL is just cross-entropy minus entropy**\n",
    "- If $P$ is known, **minimizing KL = maximizing model fit**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When to Use KL vs Cross-Entropy\n",
    "\n",
    "| Scenario | Is $P$ one-hot? | Use CE = KL? | Best Loss |\n",
    "|----------|------------------|---------------|------------|\n",
    "| Classification | ‚úÖ Yes | ‚úÖ Yes | CrossEntropyLoss |\n",
    "| Label smoothing | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "| Knowledge distillation | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "| Probabilistic models (e.g. VAEs, RL) | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Summary\n",
    "\n",
    "| Concept | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| KL Divergence | $D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log \\frac{P(i)}{Q(i)}$ | Measures inefficiency |\n",
    "| KL = CE - Entropy | $D_{\\text{KL}} = H(P, Q) - H(P)$ | When $P$ is not one-hot |\n",
    "| KL = CE (special case) | $D_{\\text{KL}} = -\\log Q(\\text{true})$ | When $P$ is one-hot |\n",
    "| MLE ‚âà KL minimization | $\\arg\\max \\log Q_\\theta(x) = \\arg\\min D_{\\text{KL}}(P \\parallel Q_\\theta)$ | Core learning principle |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Log-Softmax and the Log-Sum-Exp Trick\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ The Problem\n",
    "\n",
    "When computing:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "You're at risk of:\n",
    "\n",
    "- **Overflow** if any $z_j$ is large (e.g. $e^{1000}$)\n",
    "- **Underflow** if softmax returns very small values (log of near-zero ‚Üí $-\\infty$)\n",
    "- **NaNs** in training and gradient instability\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ The Log-Sum-Exp Trick (LSE)\n",
    "\n",
    "To stabilize:\n",
    "\n",
    "$$\n",
    "\\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "We apply:\n",
    "\n",
    "$$\n",
    "\\log \\sum_j e^{z_j} = \\max_j z_j + \\log \\sum_j e^{z_j - \\max_j z_j}\n",
    "$$\n",
    "\n",
    "This avoids numerical overflow by subtracting the largest logit before exponentiation.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Used in Practice: `log_softmax`\n",
    "\n",
    "Instead of doing:\n",
    "\n",
    "```python\n",
    "log_probs = torch.log(torch.softmax(logits, dim=-1))\n",
    "```\n",
    "\n",
    "Which is unsafe‚Ä¶\n",
    "\n",
    "Use:\n",
    "\n",
    "```python\n",
    "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "```\n",
    "\n",
    "This is:\n",
    "\n",
    "- **Numerically stable** (uses log-sum-exp trick internally)\n",
    "- **Efficient** (avoids extra computation)\n",
    "- **Safe for backprop** (no NaNs, exploding gradients)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log-Softmax Identity\n",
    "\n",
    "The math behind `log_softmax`:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "With the LSE trick applied:\n",
    "\n",
    "$$\n",
    "= z_i - \\left[ \\max_j z_j + \\log \\sum_j e^{z_j - \\max_j z_j} \\right]\n",
    "$$\n",
    "\n",
    "This ensures the entire operation is stable, even if logits are huge.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå Why You Shouldn‚Äôt Do `log(softmax(...))`\n",
    "\n",
    "| Issue                        | Result                        |\n",
    "|-----------------------------|-------------------------------|\n",
    "| $e^x$ on large logits        | Overflow / `inf`              |\n",
    "| Dividing large exponentials | Loss of precision             |\n",
    "| Taking $\\log(0)$             | `-inf`                        |\n",
    "| Manual implementation       | No use of LSE trick           |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `log_softmax` Summary\n",
    "\n",
    "| Property                  | Description                                      |\n",
    "|---------------------------|--------------------------------------------------|\n",
    "| Input                     | Raw logits (unbounded real numbers)             |\n",
    "| Output                    | Log-probabilities (sums to 1 in log space)      |\n",
    "| Implementation            | Uses log-sum-exp trick internally               |\n",
    "| Use case                  | Preferred for NLL, CE, KL, language modeling    |\n",
    "| Gradient                  | Clean: $\\nabla_{z_i} L = \\hat{y}_i - y_i$       |\n",
    "| Alternative to            | `log(softmax(z))` (don‚Äôt do this)              |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Mental Model\n",
    "\n",
    "- `softmax` ‚Üí converts scores to probs (risk of overflow)\n",
    "- `log(softmax(...))` ‚Üí unstable unless you apply LSE manually\n",
    "- `log_softmax` ‚Üí **optimized fusion** with **log-sum-exp built in**\n",
    "\n",
    "> **Moral of the story:**  \n",
    "> üíØ Always use `log_softmax` when working with log-probabilities from logits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Section 2: Partial Derivatives and Gradients\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What Is a Partial Derivative?\n",
    "\n",
    "If a function depends on multiple variables, a **partial derivative** tells you how it changes when you change **just one variable**, holding the others constant.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "f(x, y) = x^2 y + \\sin(y)\n",
    "$$\n",
    "\n",
    "- Partial derivative w.r.t. $x$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 2xy\n",
    "$$\n",
    "\n",
    "- Partial derivative w.r.t. $y$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y} = x^2 + \\cos(y)\n",
    "$$\n",
    "\n",
    "When taking $\\frac{\\partial f}{\\partial x}$, you treat $y$ like a **constant**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Notation\n",
    "\n",
    "- Regular derivative: $\\frac{df}{dx}$ ‚Äî use when $f$ has one variable  \n",
    "- Partial derivative: $\\frac{\\partial f}{\\partial x}$ ‚Äî use when $f$ has many variables\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gradient Vector\n",
    "\n",
    "If $f$ is a function of multiple variables:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2, \\dots, x_n)\n",
    "$$\n",
    "\n",
    "Then the **gradient** is the vector of all partial derivatives:\n",
    "\n",
    "$$\n",
    "\\nabla f =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\\\\\n",
    "\\vdots \\\\\\\\\n",
    "\\frac{\\partial f}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Geometric Meaning\n",
    "\n",
    "- Gradient points in the direction of **steepest ascent**  \n",
    "- In deep learning, we **move opposite the gradient** to minimize the loss\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Common Structure in DL Loss Functions\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "L = (w_1 x_1 + w_2 x_2 - y)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1} = 2(w_1 x_1 + w_2 x_2 - y) \\cdot x_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_2} = 2(w_1 x_1 + w_2 x_2 - y) \\cdot x_2\n",
    "$$\n",
    "\n",
    "This pattern appears in:\n",
    "- Linear regression  \n",
    "- MLPs  \n",
    "- Backpropagation  \n",
    "\n",
    "---\n",
    "\n",
    "### üîç Strategy for Computing Partials\n",
    "\n",
    "If:\n",
    "\n",
    "$$\n",
    "f(x, y, z) = (2x - 3y + 4z - 6)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "1. Let $a = 2x - 3y + 4z - 6$  \n",
    "2. $f = a^2$  \n",
    "3. Use chain rule:  \n",
    "   $$\n",
    "   \\frac{\\partial f}{\\partial x} = 2a \\cdot \\frac{\\partial a}{\\partial x} = 4a\n",
    "   $$  \n",
    "4. Same idea for $y$ and $z$\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Practice Prompt\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "f(x, y) = (3x + 4y - 5)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 6(3x + 4y - 5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y} = 8(3x + 4y - 5)\n",
    "$$\n",
    "\n",
    "You can distribute if you prefer:\n",
    "\n",
    "$$\n",
    "6(3x + 4y - 5) = 18x + 24y - 30\n",
    "$$\n",
    "\n",
    "$$\n",
    "8(3x + 4y - 5) = 24x + 32y - 40\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Summary\n",
    "\n",
    "| Concept | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| Partial Derivative | $\\frac{\\partial f}{\\partial x}$ | Derivative w.r.t one input |\n",
    "| Gradient Vector | $\\nabla f = [ \\frac{\\partial f}{\\partial x_1}, \\dots ]$ | All partials stacked |\n",
    "| Loss Gradient | $\\frac{\\partial L}{\\partial w} = 2(\\hat{y} - y) \\cdot x$ | Linear regression form |\n",
    "| Direction | Opposite gradient = downhill | Used in SGD & Adam |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
