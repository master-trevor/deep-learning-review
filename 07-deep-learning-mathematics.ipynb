{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Derivative Rules, Guidelines for Substitution, and Common Function Derivatives\n",
    "\n",
    "This note summarizes essential differentiation rules for deep learning, when to use substitution (aka chain rule), and how to derive common functions like sigmoid and exponentials.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Core Derivative Rules\n",
    "\n",
    "| Rule             | Description                                | Formula |\n",
    "|------------------|--------------------------------------------|---------|\n",
    "| Constant Rule     | Derivative of a constant                   | $\\frac{d}{dx}(c) = 0$ |\n",
    "| Power Rule        | For $x^n$, pull the exponent down          | $\\frac{d}{dx}(x^n) = nx^{n-1}$ |\n",
    "| Sum Rule          | Derivative of a sum = sum of derivatives   | $\\frac{d}{dx}(f + g) = f' + g'$ |\n",
    "| Product Rule      | For multiplying functions                  | $(fg)' = f'g + fg'$ |\n",
    "| Quotient Rule     | For dividing functions                     | $\\left( \\frac{f}{g} \\right)' = \\frac{f'g - fg'}{g^2}$ |\n",
    "| Chain Rule        | For composite functions $f(g(x))$          | $\\frac{d}{dx}f(g(x)) = f'(g(x)) \\cdot g'(x)$ |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Guidelines for Substitution / Chain Rule\n",
    "\n",
    "Use substitution (and chain rule) when:\n",
    "- You're differentiating a **composite function**\n",
    "- The expression includes **something more complex than plain $x$**\n",
    "- Example: $e^{-x}$, $\\log(1 + x^2)$, $\\tanh(x^3)$\n",
    "\n",
    "**Key principle:**  \n",
    "If you're not differentiating directly with respect to $x$, you're likely using the chain rule.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Chain Rule in Action (with $e^{-x}$)\n",
    "\n",
    "Let:\n",
    "- $f(x) = e^{-x}$\n",
    "- Think of this as $f(x) = e^{u(x)}$, where $u(x) = -x$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "\\frac{d}{dx}(e^{-x}) = e^{-x} \\cdot \\frac{d}{dx}(-x) = e^{-x} \\cdot (-1) = -e^{-x}\n",
    "$$\n",
    "\n",
    "‚úÖ The negative sign comes from the derivative of the inner function ($-x$).\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Derivatives of Common Functions\n",
    "\n",
    "### üî∑ Polynomials:\n",
    "- $\\frac{d}{dx}(x^2) = 2x$\n",
    "- $\\frac{d}{dx}(x^n) = nx^{n-1}$\n",
    "\n",
    "### üî∑ Exponentials:\n",
    "- $\\frac{d}{dx}(e^x) = e^x$\n",
    "- $\\frac{d}{dx}(e^{-x}) = -e^{-x}$\n",
    "- $\\frac{d}{dx}(a^x) = a^x \\log a$\n",
    "\n",
    "### üî∑ Logarithms (natural log):\n",
    "- $\\frac{d}{dx}(\\log x) = \\frac{1}{x}$\n",
    "\n",
    "### üî∑ Trigonometric (FYI only):\n",
    "- $\\frac{d}{dx}(\\sin x) = \\cos x$\n",
    "- $\\frac{d}{dx}(\\cos x) = -\\sin x$\n",
    "- $\\frac{d}{dx}(\\tan x) = \\sec^2 x$\n",
    "\n",
    "### üî∑ Hyperbolic / Neural Net Activations:\n",
    "- $\\frac{d}{dx}(\\tanh x) = 1 - \\tanh^2 x$\n",
    "- $\\frac{d}{dx}(\\text{sigmoid}(x)) = \\sigma(x)(1 - \\sigma(x))$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- Derivative rules = tools. Chain rule = glue.\n",
    "- Substitution helps identify when to apply chain rule\n",
    "- Even simple expressions like $e^{-x}$ are composite under the hood\n",
    "- Practice rewriting and differentiating in baby steps with annotations\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Activation Functions](activations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Intuition Behind Sigmoid vs Tanh in Deep Learning\n",
    "\n",
    "Understanding activation functions isn‚Äôt just about taking derivatives ‚Äî it's about how they behave **during optimization**, especially for **gradient flow**, **convergence speed**, and **vanishing gradients**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. Output Range\n",
    "\n",
    "| Function | Output Range | Zero-Centered? |\n",
    "|----------|--------------|----------------|\n",
    "| Sigmoid  | $(0, 1)$     | ‚ùå No          |\n",
    "| Tanh     | $(-1, 1)$    | ‚úÖ Yes         |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  Zero-centered outputs (like tanh) help gradients flow **positively and negatively**, making weight updates more balanced and efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. Vanishing Gradient Problem\n",
    "\n",
    "Both functions **saturate** when input $x$ is very positive or negative.\n",
    "\n",
    "| Function | Saturation Zones                  | Derivative Trend |\n",
    "|----------|-----------------------------------|------------------|\n",
    "| Sigmoid  | $x < -3$ or $x > 3$ ‚Üí flattens    | Derivative $\\approx 0$ |\n",
    "| Tanh     | $x < -3$ or $x > 3$ ‚Üí flattens    | Derivative $\\approx 0$ |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  When neurons output in these zones, their gradients vanish ‚Üí **very slow training or dead neurons** in deeper layers.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Gradient Strength\n",
    "\n",
    "| Function | Max Derivative | Location     |\n",
    "|----------|----------------|--------------|\n",
    "| Sigmoid  | $0.25$         | At $x = 0$   |\n",
    "| Tanh     | $1.0$          | At $x = 0$   |\n",
    "\n",
    "- **Why it matters:**  \n",
    "  Stronger gradients mean faster updates near $0$ ‚Äî **tanh is more expressive and efficient** in the core training zone.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4. Use Cases in Deep Learning\n",
    "\n",
    "| Use Case                        | Activation |\n",
    "|----------------------------------|------------|\n",
    "| Binary classification output     | Sigmoid    |\n",
    "| Multiclass classification output | Softmax    |\n",
    "| Hidden layers (historically)     | Tanh       |\n",
    "| Modern hidden layers             | ReLU       |\n",
    "\n",
    "- **Why tanh over sigmoid in hidden layers?**  \n",
    "  It's zero-centered and provides stronger gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 5. Why ReLU Took Over\n",
    "\n",
    "While tanh and sigmoid are still useful:\n",
    "- **ReLU** doesn‚Äôt saturate for $x > 0$\n",
    "- It keeps gradients alive\n",
    "- Great for deep networks\n",
    "- Easier to optimize\n",
    "\n",
    "But:\n",
    "- **Sigmoid** is still used in output layers\n",
    "- **Tanh + Sigmoid** still power LSTM/GRU gates\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Visual Summary\n",
    "\n",
    "#### Sigmoid & Tanh\n",
    "\n",
    "- Sigmoid squashes input to $(0, 1)$, flattens out at extremes  \n",
    "- Tanh squashes to $(-1, 1)$, symmetric and zero-centered\n",
    "\n",
    "#### Their Derivatives\n",
    "\n",
    "- **Sigmoid Derivative** peaks at $0.25$ and vanishes quickly  \n",
    "- **Tanh Derivative** peaks at $1$ and is wider around center  \n",
    "- Both die off at $|x| > 3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Activation Functions + Softmax + Cross-Entropy ‚Äî Deep Learning Intuition\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ ReLU (Rectified Linear Unit)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Keep positive values, zero out negatives.\n",
    "- Fast to compute, no saturation in the positive range.\n",
    "\n",
    "**Issues:**\n",
    "- \"Dead neurons\" ‚Äî if a neuron gets stuck negative, it may never recover.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Leaky ReLU\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha x & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "\\quad\\text{where } \\alpha \\approx 0.01 \\text{ or } 0.1\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "\\alpha & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Fixes:**\n",
    "- Lets small gradients pass through for $x < 0$ ‚Üí avoids dead neurons.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "**Exact Formula:**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "= x \\cdot \\frac{1}{2} \\left[ 1 + \\text{erf}\\left( \\frac{x}{\\sqrt{2}} \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Derivative (Exact):**\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\text{GELU}(x) = \\Phi(x) + x \\cdot \\phi(x)\n",
    "\\quad\\text{where } \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "**Approximate Formula (Used in practice):**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5x \\left[ 1 + \\tanh\\left( \\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3) \\right) \\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax + Cross-Entropy\n",
    "\n",
    "#### Softmax:\n",
    "\n",
    "Given logits vector $ \\mathbf{z} $, softmax converts to probabilities:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Cross-Entropy Loss:\n",
    "\n",
    "Given true class $ \\mathbf{y} $ (one-hot), and predicted probs $ \\hat{\\mathbf{y}} = \\text{softmax}(\\mathbf{z}) $:\n",
    "\n",
    "$$\n",
    "\\text{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "= -\\log(\\hat{y}_{\\text{true class}})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Combined Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "This is why frameworks like PyTorch use `CrossEntropyLoss(logits, targets)` directly.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Visual Intuitions\n",
    "\n",
    "- Softmax with larger logits ‚Üí more confident predictions (sharper output)\n",
    "- Cross-entropy loss:\n",
    "  - Low when $ \\hat{y}_{\\text{true}} \\approx 1 $\n",
    "  - Very high when $ \\hat{y}_{\\text{true}} \\approx 0 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Activation Functions + Softmax + Cross-Entropy ‚Äî Deep Learning Intuition (With Math)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ ReLU (Rectified Linear Unit)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Outputs the input directly if it's positive, else outputs 0.\n",
    "- Introduces non-linearity while maintaining simplicity.\n",
    "- **No gradient saturation** in the positive region ‚Üí keeps gradients alive.\n",
    "\n",
    "**Drawback:**\n",
    "- Neurons can \"die\" if they fall into the $x \\leq 0$ region (zero gradient forever).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Leaky ReLU\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha x & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "\\quad\\text{where } \\alpha \\in [0.01, 0.1]\n",
    "$$\n",
    "\n",
    "**Derivative:**\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}'(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "\\alpha & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Small negative slope instead of flat zero.\n",
    "- Allows small gradient when $x < 0$ ‚Üí avoids dead neurons.\n",
    "- Often used in GANs or deep CNNs for better convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "**Exact Formula:**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\frac{1}{2} \\left[ 1 + \\text{erf}\\left( \\frac{x}{\\sqrt{2}} \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Derivative (Exact)(Product Rule):**\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\text{GELU}(x) = \\Phi(x) + x \\cdot \\phi(x)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "**Approximate Formula (used in practice):**\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5x \\left[ 1 + \\tanh\\left( \\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3) \\right) \\right]\n",
    "$$\n",
    "\n",
    "**Intuition:**\n",
    "- Smoothed version of ReLU that uses probability weighting.\n",
    "- Weighs inputs by their likelihood of being positive under a standard normal distribution.\n",
    "- No hard threshold ‚Üí smoother gradient flow.\n",
    "\n",
    "**Use case:**\n",
    "- Default activation in Transformer models (e.g. BERT, GPT).\n",
    "- Helps with convergence and generalization in large-scale deep learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax + Cross-Entropy\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Softmax Function\n",
    "\n",
    "Given raw logits vector:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = [z_1, z_2, \\dots, z_n]\n",
    "$$\n",
    "\n",
    "Softmax converts it to a probability distribution:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "- Output: $0 < \\hat{y}_i < 1$\n",
    "- Ensures: $\\sum_i \\hat{y}_i = 1$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Cross-Entropy Loss\n",
    "\n",
    "Given one-hot encoded true label $ \\mathbf{y} $ and predicted probabilities $ \\hat{\\mathbf{y}} $, the cross-entropy loss is:\n",
    "\n",
    "$$\n",
    "\\text{CE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Since only one $ y_i = 1 $, this simplifies to:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\log(\\hat{y}_{\\text{true class}})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Log-Softmax Identity\n",
    "\n",
    "Softmax followed by log simplifies to:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "Used in practice as `log_softmax()` for **numerical stability** (avoids overflow).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Derivative of Softmax + Cross-Entropy\n",
    "\n",
    "Combined, the gradient becomes extremely clean:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "- Just the **difference between predicted and actual class**\n",
    "- Avoids needing to separately backprop through softmax and log\n",
    "- Efficient and stable ‚Äî this is why it‚Äôs **always implemented as a single combined op** in PyTorch/TF\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Visual Insights\n",
    "\n",
    "- **Softmax**:\n",
    "  - With small logit differences ‚Üí soft probability distribution\n",
    "  - With large logit differences ‚Üí sharp confidence spike\n",
    "\n",
    "- **Cross-Entropy**:\n",
    "  - Loss is **low** when the predicted probability for the true class is **close to 1**\n",
    "  - Loss is **high** when the model is confident **but wrong**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Log-Softmax: Full Derivation + Gradient\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. Recall Softmax\n",
    "\n",
    "Given logits:\n",
    "\n",
    "$$\n",
    "z = [z_1, z_2, \\dots, z_n]\n",
    "$$\n",
    "\n",
    "The softmax function is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. Derive Log-Softmax\n",
    "\n",
    "Take the log of softmax:\n",
    "\n",
    "$$\n",
    "\\log(\\hat{y}_i) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "This is the **log-softmax identity**:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Log-Softmax as a Function\n",
    "\n",
    "Let‚Äôs define:\n",
    "\n",
    "$$\n",
    "\\ell_i = \\log(\\text{softmax}(z_i)) = z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "We want to compute the derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Case 1: $i = k$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_i} =\n",
    "\\frac{\\partial}{\\partial z_i} \\left( z_i - \\log \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Split it:\n",
    "\n",
    "- First term: $ \\frac{\\partial z_i}{\\partial z_i} = 1 $\n",
    "- Second term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_i} \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "= \\frac{e^{z_i}}{\\sum_j e^{z_j}} = \\hat{y}_i\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_i} = 1 - \\hat{y}_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üî∏ Case 2: $i \\ne k$\n",
    "\n",
    "Only the second term depends on $z_k$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k} = -\\frac{\\partial}{\\partial z_k} \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "= -\\frac{e^{z_k}}{\\sum_j e^{z_j}} = -\\hat{y}_k\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4. Final Result ‚Äî Jacobian of Log-Softmax\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_i}{\\partial z_k} =\n",
    "\\begin{cases}\n",
    "1 - \\hat{y}_i & \\text{if } i = k \\\\\n",
    "-\\hat{y}_k & \\text{if } i \\ne k\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is the **Jacobian matrix** of log-softmax, and it's used in general backprop.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 5. Cross-Entropy with Log-Softmax (Combined)\n",
    "\n",
    "Cross-entropy loss:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "= -\\sum_i y_i \\cdot \\ell_i\n",
    "$$\n",
    "\n",
    "Now take derivative of $L$ w.r.t. logits $z_k$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k}\n",
    "= -\\sum_i y_i \\cdot \\frac{\\partial \\ell_i}{\\partial z_k}\n",
    "$$\n",
    "\n",
    "Now plug in the two cases from above:\n",
    "\n",
    "- When $i = k$: contributes $y_k (1 - \\hat{y}_k)$\n",
    "- When $i \\ne k$: contributes $y_i (-\\hat{y}_k)$\n",
    "\n",
    "So total derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} =\n",
    "- \\left( y_k (1 - \\hat{y}_k) + \\sum_{i \\ne k} y_i (-\\hat{y}_k) \\right)\n",
    "$$\n",
    "\n",
    "Factor out $\\hat{y}_k$:\n",
    "\n",
    "$$\n",
    "= -y_k (1 - \\hat{y}_k) + \\hat{y}_k \\sum_{i \\ne k} y_i\n",
    "$$\n",
    "\n",
    "Since $\\sum_i y_i = 1$, we know $\\sum_{i \\ne k} y_i = 1 - y_k$, so:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} =\n",
    "- y_k + \\hat{y}_k\n",
    "$$\n",
    "\n",
    "Rewritten:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Takeaway\n",
    "\n",
    "- This is why softmax + cross-entropy are **always combined**\n",
    "- The gradient simplifies to:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{z}} L = \\hat{\\mathbf{y}} - \\mathbf{y}\n",
    "$$\n",
    "\n",
    "- No need to manually backprop through softmax or log\n",
    "- Frameworks like PyTorch use this exact trick for `CrossEntropyLoss(logits, labels)`\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Summary\n",
    "\n",
    "| Component | Expression |\n",
    "|-----------|------------|\n",
    "| Log-Softmax | $ \\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j} $ |\n",
    "| $\\frac{\\partial \\ell_i}{\\partial z_k}$ | $ 1 - \\hat{y}_i$ if $i=k$, else $-\\hat{y}_k$ |\n",
    "| Cross-Entropy | $ L = -\\sum_i y_i \\log(\\hat{y}_i) $ |\n",
    "| Final Gradient | $ \\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k $ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Log of Softmax ‚Äî What It Actually Means (Step-by-Step Breakdown)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Goal:\n",
    "\n",
    "Understand the identity:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Example Logits:\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "z = [2.0, 1.0, 0.1]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Step 1: Compute Softmax\n",
    "\n",
    "The softmax formula is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "Numerically:\n",
    "\n",
    "- $e^2 \\approx 7.39$\n",
    "- $e^1 \\approx 2.72$\n",
    "- $e^{0.1} \\approx 1.105$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\sum_j e^{z_j} \\approx 7.39 + 2.72 + 1.105 = 11.215\n",
    "$$\n",
    "\n",
    "Softmax outputs:\n",
    "\n",
    "- $\\hat{y}_0 = \\frac{7.39}{11.215} \\approx 0.659$\n",
    "- $\\hat{y}_1 = \\frac{2.72}{11.215} \\approx 0.242$\n",
    "- $\\hat{y}_2 = \\frac{1.105}{11.215} \\approx 0.099$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Step 2: Take the Log of Softmax\n",
    "\n",
    "Now we compute:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log \\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= \\log(e^{z_i}) - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "= z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Numerical Example for $z_0 = 2.0$\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(2.0)) = 2.0 - \\log(11.215) \\approx 2.0 - 2.417 = -0.417\n",
    "$$\n",
    "\n",
    "Other entries:\n",
    "\n",
    "- $\\log(\\text{softmax}(1.0)) \\approx 1.0 - 2.417 = -1.417$\n",
    "- $\\log(\\text{softmax}(0.1)) \\approx 0.1 - 2.417 = -2.317$\n",
    "\n",
    "---\n",
    "\n",
    "### üß® Common Mistake Explained\n",
    "\n",
    "If you saw something like:\n",
    "\n",
    "$$\n",
    "2 - (-0.417) = 2.417 \\Rightarrow \\text{(wrong interpretation)}\n",
    "$$\n",
    "\n",
    "You probably did:\n",
    "\n",
    "$$\n",
    "2 - \\log(\\text{softmax}(2.0)) = 2 - \\log(0.659) \\approx 2 - (-0.417) = 2.417\n",
    "$$\n",
    "\n",
    "That‚Äôs **not** how log-softmax works ‚Äî that‚Äôs *backing out the log of the softmax probability*, not applying log to softmax directly.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Takeaway:\n",
    "\n",
    "To compute log-softmax **correctly**:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "This is:\n",
    "- **Numerically stable**\n",
    "- **Logically correct**\n",
    "- **Used in all deep learning frameworks** (e.g., `log_softmax()` in PyTorch)\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Combined Log-Softmax + Cross-Entropy ‚Äî Why Gradient is $\\hat{y} - y$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. What Happens Separately\n",
    "\n",
    "Logits:\n",
    "\n",
    "$$\n",
    "z = [2.0, 1.0, 0.1]\n",
    "$$\n",
    "\n",
    "Softmax:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\Rightarrow \\hat{y} \\approx [0.71, 0.21, 0.08]\n",
    "$$\n",
    "\n",
    "Cross-entropy loss with true label $y = [1, 0, 0]$:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i) = -\\log(0.71) \\approx 0.342\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. What Happens When Combined\n",
    "\n",
    "Instead of computing softmax and log separately:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "So cross-entropy becomes:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\cdot \\left(z_i - \\log \\sum_j e^{z_j}\\right)\n",
    "= -\\sum_i y_i z_i + \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. Derivative of Cross-Entropy w.r.t. Logits $z_k$\n",
    "\n",
    "Take derivative of:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i z_i + \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "Split into two parts:\n",
    "\n",
    "#### (1) First term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_k} \\left( -\\sum_i y_i z_i \\right) = -y_k\n",
    "$$\n",
    "\n",
    "#### (2) Second term:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_k} \\left( \\log \\sum_j e^{z_j} \\right) = \\frac{e^{z_k}}{\\sum_j e^{z_j}} = \\hat{y}_k\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Result:\n",
    "\n",
    "Add both parts:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k\n",
    "$$\n",
    "\n",
    "This gives you **clean, simple gradients** from raw logits ‚Äî no need to manually softmax first.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Summary\n",
    "\n",
    "| Concept                     | Formula |\n",
    "|----------------------------|---------|\n",
    "| Softmax                    | $ \\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}} $ |\n",
    "| Log-Softmax                | $ \\log(\\hat{y}_i) = z_i - \\log \\sum_j e^{z_j} $ |\n",
    "| Cross-Entropy Loss         | $ L = -\\sum_i y_i \\log(\\hat{y}_i) $ |\n",
    "| Combined Derivative        | $ \\frac{\\partial L}{\\partial z_k} = \\hat{y}_k - y_k $ |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Deep Learning Math Essentials: Exponentials, Logarithms, and Their Role in Loss Functions\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What is $e$?\n",
    "\n",
    "- $e \\approx 2.718$ is Euler's number.\n",
    "- Defined by:\n",
    "\n",
    "$$\n",
    "e = \\lim_{n \\to \\infty} \\left(1 + \\frac{1}{n} \\right)^n\n",
    "$$\n",
    "\n",
    "- Unique property:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} e^x = e^x\n",
    "$$\n",
    "\n",
    "Used heavily in deep learning because it provides smooth, always-positive, non-vanishing gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Exponential Function: $e^x$\n",
    "\n",
    "- Always positive: $e^x > 0$\n",
    "- Grows rapidly as $x \\to \\infty$\n",
    "- Flattens near zero as $x \\to -\\infty$\n",
    "- Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} e^x = e^x\n",
    "$$\n",
    "\n",
    "- Operations:\n",
    "  - $e^{a + b} = e^a \\cdot e^b$\n",
    "  - $e^{a - b} = \\frac{e^a}{e^b}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Logarithmic Function: $\\log(x)$\n",
    "\n",
    "- Inverse of $e^x$\n",
    "- Defined as:\n",
    "\n",
    "$$\n",
    "\\log(x) = y \\iff e^y = x\n",
    "$$\n",
    "\n",
    "- Only defined for $x > 0$\n",
    "- Grows slowly, explodes negatively as $x \\to 0^+$\n",
    "- Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\log(x) = \\frac{1}{x}\n",
    "$$\n",
    "\n",
    "- Operation rules:\n",
    "  - $\\log(ab) = \\log a + \\log b$\n",
    "  - $\\log\\left(\\frac{a}{b}\\right) = \\log a - \\log b$\n",
    "  - $\\log(a^b) = b \\log a$\n",
    "  - $\\log(e^x) = x$\n",
    "  - $e^{\\log(x)} = x$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Inverse Identity\n",
    "\n",
    "Exponentials and logs undo each other:\n",
    "\n",
    "$$\n",
    "\\log(e^x) = x \\quad \\text{and} \\quad e^{\\log(x)} = x\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Why Use $\\log$ and $e^x$ in Deep Learning?\n",
    "\n",
    "| Purpose                            | Example                                           | Why                         |\n",
    "|-----------------------------------|---------------------------------------------------|------------------------------|\n",
    "| Convert scores to probabilities   | $\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$ | $e^x$ exaggerates differences |\n",
    "| Stabilize products                | $\\log(p_1 \\cdot p_2) = \\log p_1 + \\log p_2$       | Avoids underflow             |\n",
    "| Gradient-based optimization       | $\\frac{d}{dx} e^x,\\ \\frac{d}{dx} \\log(x)$         | Smooth derivatives           |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Binary Cross-Entropy (BCE)\n",
    "\n",
    "Used in binary classification tasks:\n",
    "\n",
    "$$\n",
    "\\text{BCE}(\\hat{y}, y) = -[y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y \\in \\{0, 1\\}$ is the true label\n",
    "- $\\hat{y} \\in (0, 1)$ is the predicted probability\n",
    "\n",
    "Special cases:\n",
    "- If $y = 1$: $\\text{Loss} = -\\log(\\hat{y})$\n",
    "- If $y = 0$: $\\text{Loss} = -\\log(1 - \\hat{y})$\n",
    "\n",
    "Gradients:\n",
    "- If $y = 1$: $\\frac{dL}{d\\hat{y}} = -\\frac{1}{\\hat{y}}$\n",
    "- If $y = 0$: $\\frac{dL}{d\\hat{y}} = \\frac{1}{1 - \\hat{y}}$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Softmax Function\n",
    "\n",
    "Used to convert logits to a probability distribution:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}\n",
    "$$\n",
    "\n",
    "Properties:\n",
    "- $\\hat{y}_i \\in (0, 1)$\n",
    "- $\\sum_i \\hat{y}_i = 1$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Cross-Entropy Loss (Multiclass)\n",
    "\n",
    "With one-hot true labels:\n",
    "\n",
    "$$\n",
    "\\text{CE}(y, \\hat{y}) = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "If class $k$ is true, and $y_k = 1$:\n",
    "\n",
    "$$\n",
    "\\text{Loss} = -\\log(\\hat{y}_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log-Softmax Trick\n",
    "\n",
    "Instead of computing:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "$$\n",
    "\n",
    "Use:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log\\left(\\sum_j e^{z_j}\\right)\n",
    "$$\n",
    "\n",
    "This is numerically stable and gives clean gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ KL Divergence\n",
    "\n",
    "Measures how much one distribution $Q$ diverges from a true distribution $P$:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log\\left(\\frac{P(i)}{Q(i)}\\right)\n",
    "$$\n",
    "\n",
    "Can be rewritten as:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P)\n",
    "$$\n",
    "\n",
    "- $H(P, Q)$ = cross-entropy\n",
    "- $H(P)$ = entropy of true distribution\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Summary\n",
    "\n",
    "| Concept             | Formula                                                        | Use Case                     |\n",
    "|---------------------|----------------------------------------------------------------|------------------------------|\n",
    "| Exponential         | $e^x$                                                          | Amplify scores (softmax)     |\n",
    "| Logarithm           | $\\log(x)$                                                      | Stabilize, inverse of $e^x$  |\n",
    "| BCE                 | $- [y \\log(\\hat{y}) + (1-y) \\log(1 - \\hat{y})]$                | Binary classification        |\n",
    "| Softmax             | $\\hat{y}_i = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$                  | Convert logits to probs      |\n",
    "| Cross-Entropy       | $-\\sum_i y_i \\log(\\hat{y}_i)$                                   | Multiclass classification    |\n",
    "| Log-Softmax         | $z_i - \\log \\sum_j e^{z_j}$                                     | Numerically stable softmax   |\n",
    "| KL Divergence       | $\\sum_i P(i) \\log \\frac{P(i)}{Q(i)}$                            | Measure distribution mismatch|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• KL Divergence in Deep Learning ‚Äî Full Intuition + Math\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What is KL Divergence?\n",
    "\n",
    "KL divergence measures **how different** a predicted probability distribution $Q$ is from a reference (true) distribution $P$:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log \\left( \\frac{P(i)}{Q(i)} \\right)\n",
    "$$\n",
    "\n",
    "> Read as: ‚ÄúKL of $P$ relative to $Q$‚Äù\n",
    "\n",
    "- It is **not symmetric**:\n",
    "  $$\n",
    "  D_{\\text{KL}}(P \\parallel Q) \\ne D_{\\text{KL}}(Q \\parallel P)\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log Rule Breakdown\n",
    "\n",
    "We can break the KL formula using log rules:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{P(i)}{Q(i)}\\right) = \\log P(i) - \\log Q(i)\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) [\\log P(i) - \\log Q(i)] = H(P, Q) - H(P)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $H(P, Q)$ is the **cross-entropy**\n",
    "- $H(P)$ is the **entropy** of the true distribution\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When $P$ is One-Hot (Normal Classification)\n",
    "\n",
    "Let:\n",
    "$$\n",
    "P = [0, 1, 0] \\quad \\text{(true class is index 1)}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $\\log P(i)$ is only defined for $i=1$ ‚Üí others contribute 0\n",
    "- So:\n",
    "  $$\n",
    "  H(P) = -\\sum_i P(i) \\log P(i) = 0\n",
    "  $$\n",
    "\n",
    "And:\n",
    "\n",
    "$$\n",
    "H(P, Q) = -\\sum_i P(i) \\log Q(i) = -\\log Q(1)\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}(P \\parallel Q) = -\\log Q(\\text{true class})\n",
    "$$\n",
    "\n",
    "‚úÖ KL = Cross-Entropy\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When $P$ is NOT One-Hot (Soft Targets)\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "P = [0.7,\\ 0.2,\\ 0.1], \\quad Q = [0.6,\\ 0.3,\\ 0.1]\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $H(P, Q) = -\\sum_i P(i) \\log Q(i)$\n",
    "- $H(P) = -\\sum_i P(i) \\log P(i)$\n",
    "- $D_{\\text{KL}} = H(P, Q) - H(P)$\n",
    "\n",
    "Now KL $\\ne$ CE. The **difference reflects how much Q diverges from the full shape of P**, not just its top class.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Intuition\n",
    "\n",
    "- KL divergence measures the **inefficiency** of assuming $Q$ when the true distribution is $P$\n",
    "- It quantifies the **extra bits of information** needed to encode samples from $P$ using $Q$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Connection to Maximum Likelihood\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) seeks to:\n",
    "\n",
    "$$\n",
    "\\arg\\max_\\theta \\sum_x \\log Q_\\theta(x)\n",
    "$$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$\n",
    "\\arg\\min_\\theta D_{\\text{KL}}(P \\parallel Q_\\theta)\n",
    "$$\n",
    "\n",
    "‚úÖ Minimizing KL divergence = Maximizing log-likelihood\n",
    "\n",
    "They are mathematically tied:\n",
    "- **KL is just cross-entropy minus entropy**\n",
    "- If $P$ is known, **minimizing KL = maximizing model fit**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ When to Use KL vs Cross-Entropy\n",
    "\n",
    "| Scenario | Is $P$ one-hot? | Use CE = KL? | Best Loss |\n",
    "|----------|------------------|---------------|------------|\n",
    "| Classification | ‚úÖ Yes | ‚úÖ Yes | CrossEntropyLoss |\n",
    "| Label smoothing | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "| Knowledge distillation | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "| Probabilistic models (e.g. VAEs, RL) | ‚ùå No | ‚ùå No | KL Divergence |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Summary\n",
    "\n",
    "| Concept | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| KL Divergence | $D_{\\text{KL}}(P \\parallel Q) = \\sum_i P(i) \\log \\frac{P(i)}{Q(i)}$ | Measures inefficiency |\n",
    "| KL = CE - Entropy | $D_{\\text{KL}} = H(P, Q) - H(P)$ | When $P$ is not one-hot |\n",
    "| KL = CE (special case) | $D_{\\text{KL}} = -\\log Q(\\text{true})$ | When $P$ is one-hot |\n",
    "| MLE ‚âà KL minimization | $\\arg\\max \\log Q_\\theta(x) = \\arg\\min D_{\\text{KL}}(P \\parallel Q_\\theta)$ | Core learning principle |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Log-Softmax and the Log-Sum-Exp Trick\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ The Problem\n",
    "\n",
    "When computing:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = \\log\\left( \\frac{e^{z_i}}{\\sum_j e^{z_j}} \\right)\n",
    "= z_i - \\log\\left( \\sum_j e^{z_j} \\right)\n",
    "$$\n",
    "\n",
    "You're at risk of:\n",
    "\n",
    "- **Overflow** if any $z_j$ is large (e.g. $e^{1000}$)\n",
    "- **Underflow** if softmax returns very small values (log of near-zero ‚Üí $-\\infty$)\n",
    "- **NaNs** in training and gradient instability\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ The Log-Sum-Exp Trick (LSE)\n",
    "\n",
    "To stabilize:\n",
    "\n",
    "$$\n",
    "\\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "We apply:\n",
    "\n",
    "$$\n",
    "\\log \\sum_j e^{z_j} = \\max_j z_j + \\log \\sum_j e^{z_j - \\max_j z_j}\n",
    "$$\n",
    "\n",
    "This avoids numerical overflow by subtracting the largest logit before exponentiation.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Used in Practice: `log_softmax`\n",
    "\n",
    "Instead of doing:\n",
    "\n",
    "```python\n",
    "log_probs = torch.log(torch.softmax(logits, dim=-1))\n",
    "```\n",
    "\n",
    "Which is unsafe‚Ä¶\n",
    "\n",
    "Use:\n",
    "\n",
    "```python\n",
    "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "```\n",
    "\n",
    "This is:\n",
    "\n",
    "- **Numerically stable** (uses log-sum-exp trick internally)\n",
    "- **Efficient** (avoids extra computation)\n",
    "- **Safe for backprop** (no NaNs, exploding gradients)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Log-Softmax Identity\n",
    "\n",
    "The math behind `log_softmax`:\n",
    "\n",
    "$$\n",
    "\\log(\\text{softmax}(z_i)) = z_i - \\log \\sum_j e^{z_j}\n",
    "$$\n",
    "\n",
    "With the LSE trick applied:\n",
    "\n",
    "$$\n",
    "= z_i - \\left[ \\max_j z_j + \\log \\sum_j e^{z_j - \\max_j z_j} \\right]\n",
    "$$\n",
    "\n",
    "This ensures the entire operation is stable, even if logits are huge.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå Why You Shouldn‚Äôt Do `log(softmax(...))`\n",
    "\n",
    "| Issue                        | Result                        |\n",
    "|-----------------------------|-------------------------------|\n",
    "| $e^x$ on large logits        | Overflow / `inf`              |\n",
    "| Dividing large exponentials | Loss of precision             |\n",
    "| Taking $\\log(0)$             | `-inf`                        |\n",
    "| Manual implementation       | No use of LSE trick           |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ `log_softmax` Summary\n",
    "\n",
    "| Property                  | Description                                      |\n",
    "|---------------------------|--------------------------------------------------|\n",
    "| Input                     | Raw logits (unbounded real numbers)             |\n",
    "| Output                    | Log-probabilities (sums to 1 in log space)      |\n",
    "| Implementation            | Uses log-sum-exp trick internally               |\n",
    "| Use case                  | Preferred for NLL, CE, KL, language modeling    |\n",
    "| Gradient                  | Clean: $\\nabla_{z_i} L = \\hat{y}_i - y_i$       |\n",
    "| Alternative to            | `log(softmax(z))` (don‚Äôt do this)              |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Mental Model\n",
    "\n",
    "- `softmax` ‚Üí converts scores to probs (risk of overflow)\n",
    "- `log(softmax(...))` ‚Üí unstable unless you apply LSE manually\n",
    "- `log_softmax` ‚Üí **optimized fusion** with **log-sum-exp built in**\n",
    "\n",
    "> **Moral of the story:**  \n",
    "> üíØ Always use `log_softmax` when working with log-probabilities from logits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Section 2: Partial Derivatives and Gradients\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What Is a Partial Derivative?\n",
    "\n",
    "If a function depends on multiple variables, a **partial derivative** tells you how it changes when you change **just one variable**, holding the others constant.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "f(x, y) = x^2 y + \\sin(y)\n",
    "$$\n",
    "\n",
    "- Partial derivative w.r.t. $x$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 2xy\n",
    "$$\n",
    "\n",
    "- Partial derivative w.r.t. $y$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y} = x^2 + \\cos(y)\n",
    "$$\n",
    "\n",
    "When taking $\\frac{\\partial f}{\\partial x}$, you treat $y$ like a **constant**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Notation\n",
    "\n",
    "- Regular derivative: $\\frac{df}{dx}$ ‚Äî use when $f$ has one variable  \n",
    "- Partial derivative: $\\frac{\\partial f}{\\partial x}$ ‚Äî use when $f$ has many variables\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gradient Vector\n",
    "\n",
    "If $f$ is a function of multiple variables:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2, \\dots, x_n)\n",
    "$$\n",
    "\n",
    "Then the **gradient** is the vector of all partial derivatives:\n",
    "\n",
    "$$\n",
    "\\nabla f =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\\\\\n",
    "\\vdots \\\\\\\\\n",
    "\\frac{\\partial f}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Geometric Meaning\n",
    "\n",
    "- Gradient points in the direction of **steepest ascent**  \n",
    "- In deep learning, we **move opposite the gradient** to minimize the loss\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Common Structure in DL Loss Functions\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "L = (w_1 x_1 + w_2 x_2 - y)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1} = 2(w_1 x_1 + w_2 x_2 - y) \\cdot x_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_2} = 2(w_1 x_1 + w_2 x_2 - y) \\cdot x_2\n",
    "$$\n",
    "\n",
    "This pattern appears in:\n",
    "- Linear regression  \n",
    "- MLPs  \n",
    "- Backpropagation  \n",
    "\n",
    "---\n",
    "\n",
    "### üîç Strategy for Computing Partials\n",
    "\n",
    "If:\n",
    "\n",
    "$$\n",
    "f(x, y, z) = (2x - 3y + 4z - 6)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "1. Let $a = 2x - 3y + 4z - 6$  \n",
    "2. $f = a^2$  \n",
    "3. Use chain rule:  \n",
    "   $$\n",
    "   \\frac{\\partial f}{\\partial x} = 2a \\cdot \\frac{\\partial a}{\\partial x} = 4a\n",
    "   $$  \n",
    "4. Same idea for $y$ and $z$\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Practice Prompt\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "f(x, y) = (3x + 4y - 5)^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = 6(3x + 4y - 5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial y} = 8(3x + 4y - 5)\n",
    "$$\n",
    "\n",
    "You can distribute if you prefer:\n",
    "\n",
    "$$\n",
    "6(3x + 4y - 5) = 18x + 24y - 30\n",
    "$$\n",
    "\n",
    "$$\n",
    "8(3x + 4y - 5) = 24x + 32y - 40\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Summary\n",
    "\n",
    "| Concept | Formula | Notes |\n",
    "|--------|---------|-------|\n",
    "| Partial Derivative | $\\frac{\\partial f}{\\partial x}$ | Derivative w.r.t one input |\n",
    "| Gradient Vector | $\\nabla f = [ \\frac{\\partial f}{\\partial x_1}, \\dots ]$ | All partials stacked |\n",
    "| Loss Gradient | $\\frac{\\partial L}{\\partial w} = 2(\\hat{y} - y) \\cdot x$ | Linear regression form |\n",
    "| Direction | Opposite gradient = downhill | Used in SGD & Adam |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Section 3: Multivariable Chain Rule ‚Äî Core Notes\n",
    "\n",
    "---\n",
    "\n",
    "### üîß What Is the Multivariable Chain Rule?\n",
    "\n",
    "The multivariable chain rule tells you **how a scalar output changes** with respect to one input, when that input flows through **multiple dependent variables**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ General Form (One Output, Multiple Input Paths)\n",
    "\n",
    "Suppose:\n",
    "\n",
    "$$\n",
    "z = f(x, y),\\quad x = g(t),\\quad y = h(t)\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dt} = \\frac{\\partial z}{\\partial x} \\cdot \\frac{dx}{dt} + \\frac{\\partial z}{\\partial y} \\cdot \\frac{dy}{dt}\n",
    "$$\n",
    "\n",
    "Each term is a **path** from $t \\to x \\to z$ or $t \\to y \\to z$.\n",
    "\n",
    "> üîÅ You **multiply** along each path  \n",
    "> ‚ûï Then **add up** all the paths\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Real Example\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "f(x, y) = x^2 + y^2,\\quad x(t) = 3t,\\quad y(t) = t^2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $\\frac{\\partial f}{\\partial x} = 2x$  \n",
    "- $\\frac{dx}{dt} = 3$  \n",
    "- $\\frac{\\partial f}{\\partial y} = 2y$  \n",
    "- $\\frac{dy}{dt} = 2t$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{df}{dt} = 2x \\cdot 3 + 2y \\cdot 2t\n",
    "= 6x + 4yt\n",
    "$$\n",
    "\n",
    "Now plug in:\n",
    "\n",
    "- $x = 3t$\n",
    "- $y = t^2$\n",
    "\n",
    "Final result:\n",
    "\n",
    "$$\n",
    "\\frac{df}{dt} = 6(3t) + 4(t^2)(t) = 18t + 4t^3\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Application in Neural Nets (Backprop)\n",
    "\n",
    "Let:\n",
    "\n",
    "- $h = wx + b$\n",
    "- $\\hat{y} = h^2$\n",
    "- $L = (\\hat{y} - y)^2$\n",
    "\n",
    "We want to compute:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w}\n",
    "$$\n",
    "\n",
    "Use the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} =\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} \\cdot\n",
    "\\frac{\\partial \\hat{y}}{\\partial h} \\cdot\n",
    "\\frac{\\partial h}{\\partial w}\n",
    "$$\n",
    "\n",
    "Break it down:\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - y)$  \n",
    "- $\\frac{\\partial \\hat{y}}{\\partial h} = 2h$  \n",
    "- $\\frac{\\partial h}{\\partial w} = x$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = 2(\\hat{y} - y) \\cdot 2h \\cdot x = 4x h (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Takeaway\n",
    "\n",
    "> **Multivariable chain rule = multiply partial derivatives along each path from input to output.**\n",
    "\n",
    "- The core of **backpropagation** in deep learning  \n",
    "- Used whenever you have **layers** or **compositions** of functions  \n",
    "- Simple to apply once you trace the **computational graph**\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Summary Table\n",
    "\n",
    "| Path | Derivative | Meaning |\n",
    "|------|------------|---------|\n",
    "| $z \\to x \\to t$ | $\\frac{\\partial z}{\\partial x} \\cdot \\frac{dx}{dt}$ | Effect of $t$ on $z$ via $x$ |\n",
    "| $z \\to y \\to t$ | $\\frac{\\partial z}{\\partial y} \\cdot \\frac{dy}{dt}$ | Effect of $t$ on $z$ via $y$ |\n",
    "| Neural net chain | $\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial h} \\cdot \\frac{\\partial h}{\\partial w}$ | Chain of partials during backprop |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Section 3: Multivariable Chain Rule + Backprop Example\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Core Idea\n",
    "\n",
    "If a function is made up of **other functions**, the derivative of the final output with respect to some input is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x}\n",
    "$$\n",
    "\n",
    "Each step is a **partial derivative**, and you multiply them together from **output back to input**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example Setup (Backprop by Hand)\n",
    "\n",
    "Let:\n",
    "\n",
    "- $x = 2$\n",
    "- $w = 3$\n",
    "- $b = -1$\n",
    "- $y = 10$ (target)\n",
    "\n",
    "Define:\n",
    "\n",
    "- $h = \\text{ReLU}(wx + b)$\n",
    "- $\\hat{y} = h^2$\n",
    "- $L = (\\hat{y} - y)^2$\n",
    "\n",
    "We want to compute:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step-by-Step\n",
    "\n",
    "#### ‚úÖ Step 1: Forward Pass\n",
    "\n",
    "1. $h = \\text{ReLU}(3 \\cdot 2 + (-1)) = \\text{ReLU}(6 - 1) = \\text{ReLU}(5) = 5$\n",
    "2. $\\hat{y} = h^2 = 5^2 = 25$\n",
    "3. $L = (25 - 10)^2 = 225$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Step 2: Backward Pass (Chain Rule)\n",
    "\n",
    "Break down:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} =\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} \\cdot\n",
    "\\frac{\\partial \\hat{y}}{\\partial h} \\cdot\n",
    "\\frac{\\partial h}{\\partial w}\n",
    "$$\n",
    "\n",
    "Compute each part:\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial \\hat{y}} = 2(\\hat{y} - y) = 2(25 - 10) = 30$\n",
    "- $\\frac{\\partial \\hat{y}}{\\partial h} = 2h = 2 \\cdot 5 = 10$\n",
    "- $\\frac{\\partial h}{\\partial w} = x = 2$ (since $h = wx + b$ and ReLU is active)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Gradient\n",
    "\n",
    "Plug it all in:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = 30 \\cdot 10 \\cdot 2 = 600\n",
    "$$\n",
    "\n",
    "You can also write this as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = 4xh(\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "Which evaluates to:\n",
    "\n",
    "$$\n",
    "4 \\cdot 2 \\cdot 5 \\cdot (25 - 10) = 600\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary\n",
    "\n",
    "| Variable | Expression | Value |\n",
    "|----------|------------|-------|\n",
    "| $h$ | $\\text{ReLU}(wx + b)$ | 5 |\n",
    "| $\\hat{y}$ | $h^2$ | 25 |\n",
    "| $L$ | $(\\hat{y} - y)^2$ | 225 |\n",
    "| $\\frac{\\partial L}{\\partial w}$ | $4xh(\\hat{y} - y)$ | 600 |\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Key Takeaway\n",
    "\n",
    "> **Backpropagation = Chain Rule √ó Layers**\n",
    "\n",
    "- Just take the derivative of each function in the chain  \n",
    "- Multiply partials backward through the network  \n",
    "- Deep learning libraries do this automatically via autodiff (but you now know how to do it by hand üí™)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Section 4: Jacobian Matrix ‚Äî Intro & Definition\n",
    "\n",
    "---\n",
    "\n",
    "### üîß What Is the Jacobian?\n",
    "\n",
    "The **Jacobian** is the multivariable version of a derivative for functions with:\n",
    "\n",
    "- Multiple **inputs**  \n",
    "- Multiple **outputs**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ TL;DR\n",
    "\n",
    "> The Jacobian is a **matrix of partial derivatives**.  \n",
    "> It tells you how each **output** depends on each **input**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Setup\n",
    "\n",
    "Suppose:\n",
    "\n",
    "- $\\mathbf{x} \\in \\mathbb{R}^n$\n",
    "- $\\mathbf{f}(\\mathbf{x}) \\in \\mathbb{R}^m$  \n",
    "- So $\\mathbf{f}$ maps inputs to vector-valued outputs:\n",
    "\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{x}) =\n",
    "\\begin{bmatrix}\n",
    "f_1(x_1, x_2, \\dots, x_n) \\\\\\\\\n",
    "f_2(x_1, x_2, \\dots, x_n) \\\\\\\\\n",
    "\\vdots \\\\\\\\\n",
    "f_m(x_1, x_2, \\dots, x_n)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Jacobian Definition\n",
    "\n",
    "The **Jacobian matrix** $J$ is:\n",
    "\n",
    "$$\n",
    "J =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\dots & \\frac{\\partial f_1}{\\partial x_n} \\\\\\\\\n",
    "\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\dots & \\frac{\\partial f_2}{\\partial x_n} \\\\\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\frac{\\partial f_m}{\\partial x_2} & \\dots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Rows: partials of each output  \n",
    "- Columns: partials with respect to each input\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Deep Learning Interpretation\n",
    "\n",
    "- Each row is the **gradient of one output neuron**\n",
    "- Each column is how **one input affects all outputs**\n",
    "\n",
    "If:\n",
    "- $\\mathbf{x} \\in \\mathbb{R}^n$\n",
    "- $\\mathbf{f}(\\mathbf{x}) \\in \\mathbb{R}^m$  \n",
    "‚Üí Then the Jacobian is a $m \\times n$ matrix\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Why It Matters\n",
    "\n",
    "- It generalizes gradients to **vector-valued outputs**\n",
    "- Used in:\n",
    "  - Multi-class classification (softmax)\n",
    "  - Multi-output regression\n",
    "  - Intermediate layers with multiple neurons\n",
    "  - Reverse-mode autodiff\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "> Jacobian = all gradients stacked in matrix form  \n",
    "> It tells you **how the output vector changes** with the input vector.\n",
    "\n",
    "---\n",
    "\n",
    "Ready to compute one by hand?\n",
    "We‚Äôll do a clean $\\mathbb{R}^2 \\to \\mathbb{R}^2$ function next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Deep Learning Math: Jacobians in Practice\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Part 1: Jacobian of Softmax\n",
    "\n",
    "Given logits vector \\( \\mathbf{z} = [z_1, z_2, \\dots, z_n] \\), the softmax function outputs:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_k e^{z_k}} = \\frac{e^{z_i}}{S}, \\quad \\text{where } S = \\sum_k e^{z_k}\n",
    "$$\n",
    "\n",
    "We want the full Jacobian:\n",
    "\n",
    "$$\n",
    "J_{ij} = \\frac{\\partial \\hat{y}_i}{\\partial z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Case 1: \\( i = j \\)\n",
    "\n",
    "Let:\n",
    "- \\( u = e^{z_i} \\)\n",
    "- \\( v = S = \\sum_k e^{z_k} \\)\n",
    "- \\( u' = e^{z_i} \\)\n",
    "- \\( v' = e^{z_i} \\)\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_i}\n",
    "= \\frac{u' \\cdot v - u \\cdot v'}{v^2}\n",
    "= \\frac{e^{z_i} \\cdot S - e^{z_i} \\cdot e^{z_i}}{S^2}\n",
    "= \\frac{e^{z_i}}{S} \\left( 1 - \\frac{e^{z_i}}{S} \\right)\n",
    "= \\hat{y}_i (1 - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "‚úÖ This gives the **diagonal entries** of the Jacobian.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Case 2: \\( i \\ne j \\)\n",
    "\n",
    "Only the denominator changes.\n",
    "\n",
    "- \\( u = e^{z_i} \\) (constant)\n",
    "- \\( v = \\sum_k e^{z_k} \\)\n",
    "- \\( u' = 0 \\)\n",
    "- \\( v' = e^{z_j} \\)\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j}\n",
    "= \\frac{0 \\cdot S - e^{z_i} \\cdot e^{z_j}}{S^2}\n",
    "= - \\frac{e^{z_i} e^{z_j}}{S^2}\n",
    "= -\\hat{y}_i \\hat{y}_j\n",
    "$$\n",
    "\n",
    "‚úÖ These are the **off-diagonal entries**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Softmax Jacobian:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} = \\hat{y}_i (\\delta_{ij} - \\hat{y}_j)\n",
    "}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( \\delta_{ij} = 1 \\) if \\( i = j \\), else \\( 0 \\)\n",
    "- \\( \\hat{y}_i = \\text{softmax}(z_i) \\)\n",
    "\n",
    "**Matrix form:**\n",
    "\n",
    "$$\n",
    "J = \\text{diag}(\\hat{y}) - \\hat{y} \\hat{y}^T\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Part 2: Fully Connected Layers\n",
    "\n",
    "For a layer:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = W \\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "- \\( \\mathbf{x} \\in \\mathbb{R}^n \\)\n",
    "- \\( \\mathbf{y} \\in \\mathbb{R}^m \\)\n",
    "- \\( W \\in \\mathbb{R}^{m \\times n} \\)\n",
    "\n",
    "Then the Jacobian is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = W\n",
    "$$\n",
    "\n",
    "During backpropagation:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{x}} = W^\\top \\cdot \\frac{\\partial L}{\\partial \\mathbf{y}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Part 3: Intermediate Hidden Layers (e.g. ReLU)\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\mathbf{h} = \\phi(W \\mathbf{x} + \\mathbf{b})\n",
    "$$\n",
    "\n",
    "Where \\( \\phi \\) is an activation function (e.g., ReLU).  \n",
    "Then the Jacobian is a **diagonal matrix**:\n",
    "\n",
    "For ReLU:\n",
    "\n",
    "$$\n",
    "\\phi'(z_i) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } z_i > 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\quad \\Rightarrow \\quad\n",
    "J = \\text{diag}(\\phi'(z))\n",
    "$$\n",
    "\n",
    "‚úÖ This acts as a **mask** during backprop.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Summary: Jacobians in Deep Learning\n",
    "\n",
    "| Layer Type         | Jacobian                               | Notes                                           |\n",
    "|--------------------|----------------------------------------|------------------------------------------------|\n",
    "| Linear             | \\( W \\)                                | Weight matrix is the Jacobian                  |\n",
    "| ReLU               | \\( \\text{diag}(0 \\text{ or } 1) \\)     | Zeroes out inactive neurons                    |\n",
    "| Sigmoid / Tanh     | \\( \\text{diag}(\\phi'(z)) \\)            | Scales gradients by slope                      |\n",
    "| Softmax            | \\( \\text{diag}(\\hat{y}) - \\hat{y} \\hat{y}^T \\) | Redistributes probability mass           |\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why This Matters\n",
    "\n",
    "You rarely compute Jacobians manually, but understanding them helps you:\n",
    "\n",
    "- Interpret how gradients flow\n",
    "- Understand why softmax + cross-entropy gives \\( \\hat{y} - y \\)\n",
    "- Debug and design custom loss functions or layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Deriving the Gradient of Cross-Entropy Loss w.r.t. Logits (Elegant Style)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Goal\n",
    "\n",
    "We want to compute the gradient:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_j}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $z_j$ is the logit (raw model output) for class $j$\n",
    "- $L$ is the scalar cross-entropy loss for a **single datapoint**\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Setup\n",
    "\n",
    "Let:\n",
    "- Logits: $\\mathbf{z} = [z_1, z_2, \\dots, z_n]$\n",
    "- Softmax output: $\\hat{y}_i = \\frac{e^{z_i}}{\\sum_k e^{z_k}}$\n",
    "- One-hot label: $\\mathbf{y} = [y_1, y_2, \\dots, y_n]$, where $y_i = 1$ only for the correct class\n",
    "\n",
    "The loss function is:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Our goal is to compute:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Step 1: Use the Chain Rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_j}\n",
    "= \\sum_i \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Step 2: Derivative of Cross-Entropy w.r.t. Softmax Output\n",
    "\n",
    "From:\n",
    "\n",
    "$$\n",
    "L = -\\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "We get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}_i} = -\\frac{y_i}{\\hat{y}_i}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Step 3: Jacobian of Softmax\n",
    "\n",
    "We already know:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} = \\hat{y}_i (\\delta_{ij} - \\hat{y}_j)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\delta_{ij} = 1$ if $i = j$, else $0$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Step 4: Plug Into the Chain Rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_j}\n",
    "= \\sum_i \\left( -\\frac{y_i}{\\hat{y}_i} \\cdot \\hat{y}_i (\\delta_{ij} - \\hat{y}_j) \\right)\n",
    "= -\\sum_i y_i (\\delta_{ij} - \\hat{y}_j)\n",
    "$$\n",
    "\n",
    "Now expand the sum:\n",
    "\n",
    "$$\n",
    "= -\\sum_i y_i \\delta_{ij} + \\sum_i y_i \\hat{y}_j\n",
    "= -y_j + \\hat{y}_j \\cdot \\sum_i y_i\n",
    "= -y_j + \\hat{y}_j\n",
    "$$\n",
    "\n",
    "Because:\n",
    "\n",
    "$$\n",
    "\\sum_i y_i = 1 \\quad \\text{(for one-hot labels)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Final Result\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial L}{\\partial z_j} = \\hat{y}_j - y_j\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Interpretation\n",
    "\n",
    "- This tells you how much to adjust logit $z_j$ based on how wrong the prediction $\\hat{y}_j$ is.\n",
    "- If the model overpredicts ($\\hat{y}_j > y_j$), the gradient is positive ‚Üí push $z_j$ down\n",
    "- If the model underpredicts ($\\hat{y}_j < y_j$), the gradient is negative ‚Üí push $z_j$ up\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Why It's Elegant\n",
    "\n",
    "You started with:\n",
    "- A **vector function** (softmax)\n",
    "- A **scalar loss** (cross-entropy)\n",
    "\n",
    "Used the **chain rule + softmax Jacobian**, and the whole thing simplified to:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}} = \\hat{\\mathbf{y}} - \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Which is:\n",
    "- Clean ‚úÖ  \n",
    "- Efficient ‚úÖ  \n",
    "- Backprop-ready ‚úÖ\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Final Result ‚Äî Jacobian of the Softmax Function\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What Are We Doing?\n",
    "\n",
    "We want to compute the **Jacobian matrix** of the softmax function:\n",
    "\n",
    "Given logits:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = [z_1, z_2, \\dots, z_n]\n",
    "$$\n",
    "\n",
    "The softmax output is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_k e^{z_k}} = \\frac{e^{z_i}}{S}, \\quad \\text{where } S = \\sum_k e^{z_k}\n",
    "$$\n",
    "\n",
    "Our goal:  \n",
    "Compute the partial derivatives:\n",
    "\n",
    "$$\n",
    "J_{ij} = \\frac{\\partial \\hat{y}_i}{\\partial z_j}\n",
    "$$\n",
    "\n",
    "This tells us **how each softmax output** $\\hat{y}_i$ changes if we **nudge the input logit** $z_j$.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Step-by-Step Derivation\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Case 1: $i = j$\n",
    "\n",
    "We're looking at:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_i}\n",
    "$$\n",
    "\n",
    "Using the quotient rule:\n",
    "\n",
    "Let:\n",
    "- $u = e^{z_i}$\n",
    "- $v = S = \\sum_k e^{z_k}$\n",
    "- $u' = e^{z_i}$\n",
    "- $v' = e^{z_i}$ (since only one term in the sum depends on $z_i$)\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_i}\n",
    "= \\frac{u' \\cdot v - u \\cdot v'}{v^2}\n",
    "= \\frac{e^{z_i} \\cdot S - e^{z_i} \\cdot e^{z_i}}{S^2}\n",
    "$$\n",
    "\n",
    "Factor:\n",
    "\n",
    "$$\n",
    "= \\frac{e^{z_i}}{S} \\left(1 - \\frac{e^{z_i}}{S} \\right)\n",
    "= \\hat{y}_i (1 - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "‚úÖ This is the **diagonal of the Jacobian**\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Case 2: $i \\ne j$\n",
    "\n",
    "Now $z_j$ doesn‚Äôt affect the numerator $e^{z_i}$, but **does** affect the denominator:\n",
    "\n",
    "Let:\n",
    "- $u = e^{z_i}$ ‚Üí constant\n",
    "- $v = S = \\sum_k e^{z_k}$\n",
    "- $u' = 0$\n",
    "- $v' = e^{z_j}$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j}\n",
    "= \\frac{0 \\cdot S - e^{z_i} \\cdot e^{z_j}}{S^2}\n",
    "= - \\frac{e^{z_i} e^{z_j}}{S^2}\n",
    "= -\\hat{y}_i \\hat{y}_j\n",
    "$$\n",
    "\n",
    "‚úÖ These are the **off-diagonal entries**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Formula (Unified for All $i, j$):\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} = \\hat{y}_i \\left( \\delta_{ij} - \\hat{y}_j \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\delta_{ij} = 1$ if $i = j$, else $0$  \n",
    "  (this is the **Kronecker delta** ‚Äî a switch that says: ‚Äúare we on the diagonal?‚Äù)\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Matrix Form:\n",
    "\n",
    "Let $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$ be the softmax output vector. Then:\n",
    "\n",
    "- Diagonal matrix:\n",
    "\n",
    "$$\n",
    "\\text{diag}(\\hat{\\mathbf{y}}) =\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 & 0 & \\dots & 0 \\\\\n",
    "0 & \\hat{y}_2 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & \\hat{y}_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Outer product:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} \\hat{\\mathbf{y}}^\\top =\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1^2 & \\hat{y}_1 \\hat{y}_2 & \\dots \\\\\n",
    "\\hat{y}_2 \\hat{y}_1 & \\hat{y}_2^2 & \\dots \\\\\n",
    "\\vdots & \\vdots & \\ddots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So the **Jacobian of softmax is:**\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "J = \\text{diag}(\\hat{\\mathbf{y}}) - \\hat{\\mathbf{y}} \\hat{\\mathbf{y}}^\\top\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç What It Really Means:\n",
    "\n",
    "- **Diagonal entries**: $\\hat{y}_i (1 - \\hat{y}_i)$  \n",
    "  ‚Üí If I increase my own logit $z_i$, my probability goes up (but never past 1)\n",
    "\n",
    "- **Off-diagonal entries**: $-\\hat{y}_i \\hat{y}_j$  \n",
    "  ‚Üí If another logit $z_j$ increases, it steals probability mass from $z_i$\n",
    "\n",
    "---\n",
    "\n",
    "### üí° TL;DR\n",
    "\n",
    "> **Softmax Jacobian** =  \n",
    "> *\"I get a diagonal boost if I nudge my own logit...  \n",
    "> but I lose ground if any other logit rises.\"*\n",
    "\n",
    "That‚Äôs how softmax redistributes probability mass ‚Äî and why it‚Äôs perfect for multiclass classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Section 6 Summary: Vector & Matrix Derivatives (Advanced Tier)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Core Concept\n",
    "\n",
    "When dealing with vector- and matrix-valued functions in neural networks, we need to compute **gradients with respect to matrices**.\n",
    "\n",
    "This section covers:\n",
    "\n",
    "- Derivatives of the form $y = Wx + b$\n",
    "- Applying chain rule to matrix expressions\n",
    "- Deriving gradients for fully connected layers\n",
    "- Connecting to softmax + cross-entropy gradients\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 1. Derivative of a Linear Layer\n",
    "\n",
    "Given:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = W \\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $W \\in \\mathbb{R}^{C \\times D}$: weights\n",
    "- $\\mathbf{x} \\in \\mathbb{R}^D$: input\n",
    "- $\\mathbf{b} \\in \\mathbb{R}^C$: bias\n",
    "- $\\mathbf{z} \\in \\mathbb{R}^C$: output logits\n",
    "\n",
    "And we compute loss $L$ based on $\\mathbf{z}$.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Goal: Compute Gradients\n",
    "\n",
    "We want:\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial W}$\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{b}}$\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{x}}$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 2. Chain Rule: Backprop Through the Linear Layer\n",
    "\n",
    "Assume you already have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}} = \\hat{\\mathbf{y}} - \\mathbf{y} \\quad \\text{(from softmax + cross-entropy)}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gradient w.r.t. Weights\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W}\n",
    "= \\frac{\\partial L}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial W}\n",
    "= (\\hat{\\mathbf{y}} - \\mathbf{y}) \\cdot \\mathbf{x}^\\top\n",
    "$$\n",
    "\n",
    "Shape:  \n",
    "- $(C \\times 1) \\cdot (1 \\times D) = C \\times D$\n",
    "\n",
    "This is an **outer product**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gradient w.r.t. Bias\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{b}} = \\frac{\\partial L}{\\partial \\mathbf{z}} = \\hat{\\mathbf{y}} - \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Because $\\mathbf{b}$ adds directly into $\\mathbf{z}$ with a derivative of 1.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Gradient w.r.t. Input\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{x}} = W^\\top \\cdot \\frac{\\partial L}{\\partial \\mathbf{z}}\n",
    "= W^\\top (\\hat{\\mathbf{y}} - \\mathbf{y})\n",
    "$$\n",
    "\n",
    "Shape:  \n",
    "- $(D \\times C) \\cdot (C \\times 1) = D \\times 1$\n",
    "\n",
    "This pushes the error signal **backward** to earlier layers.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 3. General Update Rule\n",
    "\n",
    "Once you have all gradients, apply gradient descent:\n",
    "\n",
    "- Update weights:\n",
    "\n",
    "  $$\n",
    "  W := W - \\eta \\cdot \\frac{\\partial L}{\\partial W}\n",
    "  $$\n",
    "\n",
    "- Update bias:\n",
    "\n",
    "  $$\n",
    "  \\mathbf{b} := \\mathbf{b} - \\eta \\cdot \\frac{\\partial L}{\\partial \\mathbf{b}}\n",
    "  $$\n",
    "\n",
    "Where $\\eta$ is the learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 4. Intuition & Structure\n",
    "\n",
    "- Matrix calculus makes **gradient shapes and flows** clear\n",
    "- You can visualize:\n",
    "  - Outer products ‚Üí building gradients row-by-row\n",
    "  - Dot products ‚Üí collapsing contributions layer-by-layer\n",
    "- This makes it easier to debug dimensions in deep nets\n",
    "\n",
    "---\n",
    "\n",
    "### üß† TL;DR: Backprop Through a Linear Layer\n",
    "\n",
    "Given:\n",
    "\n",
    "$$\n",
    "\\mathbf{z} = W \\mathbf{x} + \\mathbf{b}\n",
    "\\quad \\text{and} \\quad\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}} = \\hat{\\mathbf{y}} - \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial W} = (\\hat{\\mathbf{y}} - \\mathbf{y}) \\cdot \\mathbf{x}^\\top$\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{b}} = \\hat{\\mathbf{y}} - \\mathbf{y}$\n",
    "- $\\frac{\\partial L}{\\partial \\mathbf{x}} = W^\\top (\\hat{\\mathbf{y}} - \\mathbf{y})$\n",
    "\n",
    "These formulas are the **foundation of backpropagation** in feedforward networks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
